{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "import config\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tacobox import Taco\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import Compose, ConvertImageDtype, Pad, Resize, PILToTensor\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import pandas as pd\n",
    "from utils import create_simple_splits, create_multiple_splits, get_IAM_statistics, get_base_statistics, get_bhk_features\n",
    "from path import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IAMDL(Dataset):\n",
    "\n",
    "    def __init__(self, model_set : str, path : str, batch_size, device):\n",
    "        assert model_set == 'test' or model_set == 'train' or model_set == 'validation'\n",
    "        model_set += '.uttlist'\n",
    "        self.path = path\n",
    "        self.set = IAM / 'LWRT' / model_set\n",
    "        self.batchSize = batch_size\n",
    "        self.samples = []\n",
    "        self.set_samples = self.__get_set_samples()\n",
    "        self.max_width, self.max_height = get_IAM_statistics()\n",
    "        self.device = device\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.set_samples)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.set_samples[index]\n",
    "    \n",
    "    def __get_set_samples(self):\n",
    "        set_samples = []\n",
    "        # for author in os.listdir(self.set):\n",
    "        #     writings = os.path.join(self.set, author)\n",
    "        #     for png in os.listdir(writings):\n",
    "        #             set_samples.append(os.path.join(writings, png))\n",
    "        f = open(self.path + 'sentences.txt')\n",
    "        chars = set()\n",
    "        for line in f:\n",
    "            if not line or line[0]=='#':\n",
    "                continue\n",
    "            lineSplit = line.strip().split(' ')\n",
    "            assert len(lineSplit) >= 9\n",
    "            fileNameSplit = lineSplit[0].split('-')\n",
    "            fileName = self.path + 'sentences/' + fileNameSplit[0] + '/' +\\\n",
    "                       fileNameSplit[0] + '-' + fileNameSplit[1] + '/' + lineSplit[0] + '.png'\n",
    "            self.samples.append(fileName)\n",
    "        \n",
    "        folders = [x.strip(\"\\n\") for x in open(self.set).readlines()]\n",
    "\n",
    "        for i in range(0, len(self.samples)):\n",
    "            file = self.samples[i].split(\"/\")[-1][:-4].strip(\" \")\n",
    "            folder = \"-\".join(file.split(\"-\")[:-2])\n",
    "            if (folder in folders): \n",
    "                self.set_samples.append(self.samples[i])\n",
    "        return set_samples\n",
    "    \n",
    "    # def preprocess(self, img, augment=True):\n",
    "    #     if augment:\n",
    "    #         img = self.apply_taco_augmentations(img)\n",
    "            \n",
    "    #     # scaling image [0, 1]\n",
    "    #     img = img/255\n",
    "    #     img = img.swapaxes(-2,-1)[...,::-1]\n",
    "    #     target = np.ones((config.INPUT_WIDTH, config.INPUT_HEIGHT))\n",
    "    #     new_x = config.INPUT_WIDTH/img.shape[0]\n",
    "    #     new_y = config.INPUT_HEIGHT/img.shape[1]\n",
    "    #     min_xy = min(new_x, new_y)\n",
    "    #     new_x = int(img.shape[0]*min_xy)\n",
    "    #     new_y = int(img.shape[1]*min_xy)\n",
    "    #     img2 = cv2.resize(img, (new_y,new_x))\n",
    "    #     target[:new_x,:new_y] = img2\n",
    "    #     return 1 - (target)\n",
    "    \n",
    "    # def apply_taco_augmentations(self, input_img):\n",
    "    #     random_value = random.random()\n",
    "    #     if random_value <= config.TACO_AUGMENTAION_FRACTION:\n",
    "    #         augmented_img = self.mytaco.apply_vertical_taco(\n",
    "    #             input_img, \n",
    "    #             corruption_type='random'\n",
    "    #         )\n",
    "    #     else:\n",
    "    #         augmented_img = input_img\n",
    "    #     return augmented_img\n",
    "    \n",
    "    def get_triplet(self, sample):\n",
    "        pos_aut = '/'.join(sample.split(\"/\")[:-1])\n",
    "        anc_img = sample.split(\"/\")[-1]\n",
    "        pos_img = random.choice([a for a in os.listdir(pos_aut)])\n",
    "        while(pos_img == anc_img):\n",
    "            pos_img = random.choice([a for a in os.listdir(pos_aut)])\n",
    "\n",
    "        neg_aut = os.path.join(self.path + 'sentences', random.choice([a for a in os.listdir(self.path + 'sentences')]))\n",
    "        neg_aut = os.path.join(neg_aut, random.choice([a for a in os.listdir(neg_aut)]))\n",
    "        while(pos_aut == neg_aut):\n",
    "            neg_aut = os.path.join(self.path + 'sentences', random.choice([a for a in os.listdir(self.path + 'sentences')]))\n",
    "            neg_aut = os.path.join(neg_aut, random.choice([a for a in os.listdir(neg_aut)]))\n",
    "        neg_img = random.choice([a for a in os.listdir(neg_aut)])\n",
    "\n",
    "        anchor_img = Image.open(os.path.join(pos_aut, anc_img))\n",
    "        anchor_w, anchor_h = anchor_img.size\n",
    "        transform = Compose([\n",
    "            PILToTensor(),\n",
    "            ConvertImageDtype(torch.float),\n",
    "            Pad((0, 0, self.max_width - anchor_w, self.max_height - anchor_h), fill=1.),\n",
    "            Resize((128, 1024))\n",
    "        ])\n",
    "        anchor = transform(anchor_img)\n",
    "\n",
    "        positive_img = Image.open(os.path.join(pos_aut, pos_img))\n",
    "        positive_w, positive_h = positive_img.size\n",
    "        transform = Compose([\n",
    "            PILToTensor(),\n",
    "            ConvertImageDtype(torch.float),\n",
    "            Pad((0, 0, self.max_width - positive_w, self.max_height - positive_h), fill=1.),\n",
    "            Resize((128, 1024))\n",
    "        ])\n",
    "        positive = transform(positive_img)\n",
    "\n",
    "        negative_img = Image.open(os.path.join(neg_aut, neg_img))\n",
    "        negative_w, negative_h = negative_img.size\n",
    "        transform = Compose([\n",
    "            PILToTensor(),\n",
    "            ConvertImageDtype(torch.float),\n",
    "            Pad((0, 0, self.max_width - negative_w, self.max_height - negative_h), fill=1.),\n",
    "            Resize((128, 1024))\n",
    "        ])\n",
    "        negative = transform(negative_img)\n",
    "\n",
    "        return anchor, positive, negative\n",
    "    \n",
    "    def batch_triplets(self, samples):\n",
    "        \n",
    "        batch_size = len(samples)\n",
    "        anchors = torch.empty(size=(batch_size, 1, 128, 1024))\n",
    "        positives = torch.empty(size=(batch_size, 1, 128, 1024))\n",
    "        negatives = torch.empty(size=(batch_size, 1, 128, 1024))\n",
    "        \n",
    "        for batch, sample in enumerate(samples):\n",
    "            anchors[batch], positives[batch], negatives[batch] = self.get_triplet(sample)\n",
    "        \n",
    "        return anchors.to(self.device), positives.to(self.device), negatives.to(self.device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
