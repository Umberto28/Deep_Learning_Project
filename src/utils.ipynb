{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Funzioni utili**\n",
    "Definiamo alcune funzioni per la suddivisione ed il calcolo di alcune statistiche dei dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "from torchvision.transforms.functional import pil_to_tensor, resize\n",
    "from torch.nn.functional import pad\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "from sklearn import preprocessing\n",
    "%run path.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Statistiche IAM**\n",
    "Questa funzione scorre tutto il dataset IAM e calcola le dimensioni massime raggiunte dalle immagini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_IAM_statistics():\n",
    "    h = []\n",
    "    w = []\n",
    "    # images = []\n",
    "    main_dir = IAM + '/sentences'\n",
    "    for dir in os.listdir(main_dir):\n",
    "        dir_path = os.path.join(main_dir, dir)\n",
    "        for subdir in os.listdir(dir_path):\n",
    "            subdir_path = os.path.join(dir_path, subdir)\n",
    "            for image in os.listdir(subdir_path):\n",
    "                img_path = os.path.join(subdir_path, image)\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                # images.append(resize(pil_to_tensor(img) / 255., (128, 1024)))\n",
    "                img_size = img.size\n",
    "                h.append(img_size[1])\n",
    "                w.append(img_size[0])\n",
    "    # images = torch.stack(images, dim=0)\n",
    "    # mean = torch.mean(images)\n",
    "    # std = torch.std(images)\n",
    "\n",
    "    # print(mean, std)\n",
    "    \n",
    "    return max(w), max(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Statistiche Dysgraphia**\n",
    "Questa funzione scorre tutto il dataset Dysgraphia e calcola le dimensioni massime raggiunte dalle immagini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_statistics(aug : bool = False):\n",
    "    h = []\n",
    "    w = []\n",
    "    \n",
    "    if aug == True:\n",
    "        main_dir = ADYSG\n",
    "    else:\n",
    "        main_dir = DYSG\n",
    "    \n",
    "    for dir in os.listdir(main_dir):\n",
    "        dir_path = os.path.join(main_dir, dir)\n",
    "        for image in os.listdir(dir_path):\n",
    "            img_path = os.path.join(dir_path, image)\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            # images.append(resize(pil_to_tensor(img) / 255., (128, 1024)))\n",
    "            img_size = img.size\n",
    "            h.append(img_size[1])\n",
    "            w.append(img_size[0])\n",
    "    # images = torch.stack(images, dim=0)\n",
    "    # mean = torch.mean(images)\n",
    "    # std = torch.std(images)\n",
    "\n",
    "    # print(mean, std)\n",
    "    \n",
    "    return max(w), max(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Suddivisione Dysgraphia**\n",
    "Questa funzione suddivide il dataset etichettato Dysgraphia in train, test e validation set e li salva in file di testo, successivamente considerati dall'architettura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_splits(path : str):\n",
    "    if os.path.isdir(os.path.join(path, 'train.txt')):\n",
    "        return\n",
    "    else:\n",
    "        print(\"Creating Simple splits.\")\n",
    "    \n",
    "    dis = [filename for filename in os.listdir(str(path) + \"/Dysgraphic1\") and os.listdir(str(path) + \"/Dysgraphic2\")]\n",
    "    not_dis = [filename for filename in os.listdir(str(path) + \"/No_Dysgraphic1\") and os.listdir(str(path) + \"/No_Dysgraphic2\")]\n",
    "\n",
    "    print(len(dis))\n",
    "    print(len(not_dis))\n",
    "\n",
    "    test_dis = random.sample(dis, 3)\n",
    "    validation = [random.choice(test_dis)]\n",
    "    test_dis.remove(validation[0])\n",
    "\n",
    "    test_not_dis = random.sample(not_dis, 3)\n",
    "    validation.append(random.choice(test_not_dis))\n",
    "    test_not_dis.remove(validation[1])\n",
    "\n",
    "    test_dis.extend(test_not_dis)\n",
    "    train = [filename for filename in os.listdir(path) if filename not in test_dis]\n",
    "\n",
    "    with open(os.path.join('/'.join(str(path).split(\"/\")[:-1]), 'train.txt'), 'w') as f:\n",
    "        for t in train:\n",
    "            f.write(f\"{t}\\n\")\n",
    "    \n",
    "    with open(os.path.join('/'.join(str(path).split(\"/\")[:-1]), 'validation.txt'), 'w') as f:\n",
    "        for t in validation:\n",
    "            f.write(f\"{t}\\n\")\n",
    "\n",
    "    with open(os.path.join('/'.join(str(path).split(\"/\")[:-1]), 'test.txt'), 'w') as f:\n",
    "        for t in test_dis:\n",
    "            f.write(f\"{t}\\n\")\n",
    "\n",
    "# dataset_path = ADYSG\n",
    "# create_simple_splits(dataset_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
