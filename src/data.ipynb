{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Definizione dei Dataset**\n",
    "Creiamo due classi differenti utilizzate per gestire i due dataset utilizzati dal modello: il dataset IAM a il nostro dataset con immagini etichettate (se rappresentano o meno la scrittura di un soggetto disgrafico)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "# from tacobox import Taco\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import Compose, ConvertImageDtype, Pad, Resize, PILToTensor\n",
    "%run utils.ipynb\n",
    "%run path.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Dataset IAM**\n",
    "Questa classe gestisce le immagini del dataset IAM per il pretraining dell'architettura, suddividendo le immagini in train, test e validation set. Viene calcolata inoltre una funzione di loss definita come 'Triplet loss'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IAMDL(Dataset):\n",
    "\n",
    "    def __init__(self, model_set : str, path : str):\n",
    "        assert model_set == 'test' or model_set == 'train' or model_set == 'validation'\n",
    "        model_set += '.uttlist'\n",
    "        self.path = path\n",
    "        self.set = path + '/LWRT/' + model_set\n",
    "        self.samples = []\n",
    "        self.set_samples = self.__get_set_samples()\n",
    "        self.max_width, self.max_height = get_IAM_statistics()\n",
    "        self.device = 'cpu'\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.set_samples)\n",
    "    \n",
    "    def __getitem__(self, index : int):\n",
    "        return self.set_samples[index]\n",
    "    \n",
    "    def __get_set_samples(self):\n",
    "        set_samples = []\n",
    "        f = open(self.path + '/sentences.txt')\n",
    "\n",
    "        for line in f:\n",
    "            if not line or line[0]=='#':\n",
    "                continue\n",
    "            lineSplit = line.strip().split(' ')\n",
    "            assert len(lineSplit) >= 9\n",
    "            fileNameSplit = lineSplit[0].split('-')\n",
    "            fileName = self.path + '/sentences/' + fileNameSplit[0] + '/' + fileNameSplit[0] + '-' + fileNameSplit[1] + '/' + lineSplit[0] + '.png'\n",
    "            self.samples.append(fileName)\n",
    "        \n",
    "        folders = [x.strip(\"\\n\") for x in open(self.set).readlines()]\n",
    "\n",
    "        for i in range(0, len(self.samples)):\n",
    "            file = self.samples[i].split(\"/\")[-1][:-4].strip(\" \")\n",
    "            folder = \"-\".join(file.split(\"-\")[:-2])\n",
    "            if (folder in folders): \n",
    "                set_samples.append(self.samples[i])\n",
    "        return set_samples\n",
    "    \n",
    "    def get_triplet(self, sample):\n",
    "        pos_aut = '/'.join(sample.split(\"/\")[:-1])\n",
    "        anc_img = sample.split(\"/\")[-1]\n",
    "        pos_img = random.choice([a for a in os.listdir(pos_aut)])\n",
    "        while(pos_img == anc_img):\n",
    "            pos_img = random.choice([a for a in os.listdir(pos_aut)])\n",
    "\n",
    "        neg_aut = os.path.join(self.path + '/sentences', random.choice([a for a in os.listdir(self.path + '/sentences')]))\n",
    "        neg_aut = os.path.join(neg_aut, random.choice([a for a in os.listdir(neg_aut)]))\n",
    "        while(pos_aut == neg_aut):\n",
    "            neg_aut = os.path.join(self.path + '/sentences', random.choice([a for a in os.listdir(self.path + '/sentences')]))\n",
    "            neg_aut = os.path.join(neg_aut, random.choice([a for a in os.listdir(neg_aut)]))\n",
    "        neg_img = random.choice([a for a in os.listdir(neg_aut)])\n",
    "\n",
    "        anchor_img = Image.open(os.path.join(pos_aut, anc_img))\n",
    "        anchor_w, anchor_h = anchor_img.size\n",
    "        transform = Compose([\n",
    "            PILToTensor(),\n",
    "            ConvertImageDtype(torch.float),\n",
    "            Pad((0, 0, self.max_width - anchor_w, self.max_height - anchor_h), fill=1.),\n",
    "            Resize((128, 1024))\n",
    "        ])\n",
    "        anchor = transform(anchor_img)\n",
    "\n",
    "        positive_img = Image.open(os.path.join(pos_aut, pos_img))\n",
    "        positive_w, positive_h = positive_img.size\n",
    "        transform = Compose([\n",
    "            PILToTensor(),\n",
    "            ConvertImageDtype(torch.float),\n",
    "            Pad((0, 0, self.max_width - positive_w, self.max_height - positive_h), fill=1.),\n",
    "            Resize((128, 1024))\n",
    "        ])\n",
    "        positive = transform(positive_img)\n",
    "\n",
    "        negative_img = Image.open(os.path.join(neg_aut, neg_img))\n",
    "        negative_w, negative_h = negative_img.size\n",
    "        transform = Compose([\n",
    "            PILToTensor(),\n",
    "            ConvertImageDtype(torch.float),\n",
    "            Pad((0, 0, self.max_width - negative_w, self.max_height - negative_h), fill=1.),\n",
    "            Resize((128, 1024))\n",
    "        ])\n",
    "        negative = transform(negative_img)\n",
    "\n",
    "        return anchor, positive, negative\n",
    "    \n",
    "    def batch_triplets(self, samples):\n",
    "        \n",
    "        batch_size = len(samples)\n",
    "        anchors = torch.empty(size=(batch_size, 1, 128, 1024))\n",
    "        positives = torch.empty(size=(batch_size, 1, 128, 1024))\n",
    "        negatives = torch.empty(size=(batch_size, 1, 128, 1024))\n",
    "        \n",
    "        for batch, sample in enumerate(samples):\n",
    "            anchors[batch], positives[batch], negatives[batch] = self.get_triplet(sample)\n",
    "        \n",
    "        return anchors.to(self.device), positives.to(self.device), negatives.to(self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Dataset Dysgraphia**\n",
    "Questa classe, invece, gestisce le immagini del nostro dataset etichettato per il training e test dell'architettura, suddividendo anch'esso le immagini in train, test e validation set. Inoltre, consideriamo due casi: dataset senza augmentation e dataset con augmentation (tecniche tradizionali o taco augmentation, pi√π info nella relazione)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DysgraphiaDL(Dataset):\n",
    "\n",
    "    def __init__(self, aug :  str, model_set : str, device : str):\n",
    "        assert model_set == 'train' or model_set == 'val' or model_set == 'test'\n",
    "        create_simple_splits(DYSG, aug)\n",
    "\n",
    "        self.BASE = DYSG\n",
    "        self.set = model_set + f'_{aug}.txt'\n",
    "        self.set_samples = self.__set_samples()\n",
    "        self.max_width, self.max_height = get_base_statistics(aug)\n",
    "        self.device = device\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.set_samples)\n",
    "    \n",
    "    def __getitem__(self, index : int):\n",
    "        img = Image.open(self.set_samples[index]).convert('L')\n",
    "        transform = Compose([\n",
    "            PILToTensor(),\n",
    "            ConvertImageDtype(torch.float),\n",
    "            Pad((0, 0, self.max_width - img.size[0], self.max_height - img.size[1]), fill=1.),\n",
    "            Resize((192, 512))\n",
    "        ])\n",
    "        img = transform(img)\n",
    "        \n",
    "\n",
    "        if 'No_Dysgraphic' in self.set_samples[index].split(\"/\")[1] : \n",
    "            label = torch.tensor(0)\n",
    "        else: \n",
    "            label = torch.tensor(1)\n",
    "        \n",
    "        return img.to(self.device), label.to(self.device), torch.empty((1))\n",
    "    \n",
    "    def __set_samples(self):\n",
    "        f = open(SPLIT + \"/\" + self.set)\n",
    "\n",
    "        set_samples = [line.replace(\"\\n\",\"\") for line in f]\n",
    "\n",
    "        return set_samples\n",
    "    \n",
    "    def get_binary_weights(self):\n",
    "        counter = [0, 0]\n",
    "        for sample in self.set_samples:\n",
    "            author = sample.split(\"/\")[-2]\n",
    "            label = self.labels_csv.filter(like=self.labels.upper()).loc[author].values[0]\n",
    "            if label == 0: counter[0] += 1\n",
    "            else: counter[1] += 1\n",
    "        \n",
    "        print(f\"Samples per class: {counter}\")\n",
    "        print(f\"Values: {[min(counter) / counter[0], min(counter) / counter[1]]}\")\n",
    "        \n",
    "        return torch.tensor([min(counter) / counter[0], min(counter) / counter[1]]).to(self.device)\n",
    "    \n",
    "    # def preprocess(self, img, augment=True):\n",
    "    #     if augment:\n",
    "    #         img = self.apply_taco_augmentations(img)\n",
    "            \n",
    "    #     # scaling image [0, 1]\n",
    "    #     img = img/255\n",
    "    #     img = img.swapaxes(-2,-1)[...,::-1]\n",
    "    #     target = np.ones((config.INPUT_WIDTH, config.INPUT_HEIGHT))\n",
    "    #     new_x = config.INPUT_WIDTH/img.shape[0]\n",
    "    #     new_y = config.INPUT_HEIGHT/img.shape[1]\n",
    "    #     min_xy = min(new_x, new_y)\n",
    "    #     new_x = int(img.shape[0]*min_xy)\n",
    "    #     new_y = int(img.shape[1]*min_xy)\n",
    "    #     img2 = cv2.resize(img, (new_y,new_x))\n",
    "    #     target[:new_x,:new_y] = img2\n",
    "    #     return 1 - (target)\n",
    "    \n",
    "    # def apply_taco_augmentations(self, input_img):\n",
    "    #     random_value = random.random()\n",
    "    #     if random_value <= config.TACO_AUGMENTAION_FRACTION:\n",
    "    #         augmented_img = self.mytaco.apply_vertical_taco(\n",
    "    #             input_img, \n",
    "    #             corruption_type='random'\n",
    "    #         )\n",
    "    #     else:\n",
    "    #         augmented_img = input_img\n",
    "    #     return augmented_img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
