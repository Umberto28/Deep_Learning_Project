{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Funzioni utili**\n",
    "Definiamo alcune funzioni per la suddivisione ed il calcolo di alcune statistiche dei dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, root_mean_squared_error\n",
    "import shap\n",
    "from torch.nn import Sigmoid, BCELoss\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from math import inf\n",
    "from datetime import timedelta\n",
    "from mlxtend.evaluate import accuracy_score\n",
    "%run path.ipynb\n",
    "%run model.ipynb\n",
    "%run data.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "\n",
    "    # LOAD DATA\n",
    "    model_name = f'{args.model}_split{args.split}'\n",
    " \n",
    "    train_data = DysgraphiaDL(args.aug, 'train', DEVICE)\n",
    "    validation_data = DysgraphiaDL(args.aug, 'val', DEVICE)\n",
    "    \n",
    "    # LOAD MODEL\n",
    "    if args.model == 'vit':\n",
    "        wrapper = ViTWrapper(model_name, DEVICE, 2, False)\n",
    "    elif args.model == 'resnet':\n",
    "        wrapper = ResnetWrapper(model_name, DEVICE, 2, False)\n",
    "    else:\n",
    "        raise Exception(f'{model} is not a model: selecte either vit or resnet.')\n",
    "    \n",
    "    wrapper.binary()\n",
    "    if args.freeze: wrapper.freeze()\n",
    "    model = wrapper.get_model()\n",
    "\n",
    "    print(model)\n",
    "\n",
    "    # TRAIN SETTINGS\n",
    "    epochs = 150\n",
    "    start_epoch = 0\n",
    "    batch_size = 8\n",
    "    best_val_loss = inf\n",
    "    best_val_crit = inf\n",
    "    exit_counter = 0\n",
    "    epsilon = 0.001 # counter guard precision improovement\n",
    "    lr = 0.00001\n",
    "\n",
    "    act = Sigmoid()\n",
    "    func = BCELoss()\n",
    "    loss = lambda x, y: func(torch.reshape(act(x), (-1,)), y.type(torch.float32))\n",
    "\n",
    "    opt = optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    if args.resume_iam:\n",
    "        start_epoch, best_val_loss, exit_counter, opt_chk, best_val_crit = wrapper.resume(f'{model_name}_checkpoint.pth')\n",
    "        opt.load_state_dict(opt_chk)\n",
    "\n",
    "    if args.resume:\n",
    "        start_epoch, best_val_loss, exit_counter, opt_chk, best_val_crit = wrapper.resume(f'{args.model}_checkpoint.pth')\n",
    "        opt.load_state_dict(opt_chk)\n",
    "\n",
    "    print('Start Training')\n",
    "    for e in range(start_epoch, epochs):\n",
    "\n",
    "        # TRAIN\n",
    "        model.train()\n",
    "        loader = iter(DataLoader(train_data, batch_size=batch_size, shuffle=True))\n",
    "        train_loss = 0.0\n",
    "        running_loss = 0.0\n",
    "        train_crit = 0.0\n",
    "        running_crit = 0.0\n",
    "\n",
    "        start = time.time()\n",
    "        for i in range(0, int(len(train_data) / batch_size) + 1):\n",
    "            images, classes, pfeat = next(loader)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            preds = model(images)\n",
    "\n",
    "            out = loss(preds, classes)\n",
    "            out.backward()\n",
    "            opt.step()\n",
    "\n",
    "            train_loss += out.item()\n",
    "            running_loss += out.item()\n",
    "\n",
    "            classes = np.asarray(classes.cpu())\n",
    "\n",
    "            preds = torch.reshape(act(preds), (-1,)).cpu().detach().numpy()\n",
    "            crit = root_mean_squared_error(classes, preds)\n",
    "            train_crit += crit\n",
    "            running_crit += crit\n",
    "\n",
    "            if i % 5 == 4:\n",
    "                print(f'Epoch {e + 1} - Batch {i + 1}: Running Loss {running_loss / 5} / Running Criteria {running_crit / 5}', end='\\r')\n",
    "                running_loss = 0.0\n",
    "                running_crit = 0.0\n",
    "        \n",
    "        train_loss = train_loss / i\n",
    "        train_crit = train_crit / i\n",
    "        print(f'Epoch {e + 1}: Train Loss {train_loss} - Train Criteria {train_crit} - Time {str(timedelta(seconds=time.time() - start))}')\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loader = iter(DataLoader(validation_data, batch_size=len(validation_data), shuffle=False))\n",
    "            images, classes, pfeat = next(loader)\n",
    "            preds  = model(images)\n",
    "            out = loss(preds, classes)\n",
    "            \n",
    "            classes = np.asarray(classes.cpu())\n",
    "           \n",
    "            preds = torch.reshape(act(preds), (-1,)).cpu()\n",
    "            crit = root_mean_squared_error(classes, preds)\n",
    "\n",
    "            val_crit = crit\n",
    "            print(f\"Epoch {e + 1}: Validation Loss {out.item()} - Validation Criteria {val_crit}\")\n",
    "            if val_crit < best_val_crit - epsilon:\n",
    "                print(f\"    !- Validation improovement! {best_val_crit} -> {val_crit}\")\n",
    "                exit_counter = 0\n",
    "                best_val_crit = val_crit\n",
    "                is_best = True\n",
    "            else:\n",
    "                print(f\"    !- No improovement!\")\n",
    "                is_best = False\n",
    "                exit_counter += 1\n",
    "            \n",
    "            state = {\n",
    "                'epoch': e + 1,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'exit_counter': exit_counter,\n",
    "                'optimizer': opt.state_dict(),\n",
    "                'best_val_crit': best_val_crit\n",
    "            }\n",
    "            wrapper.save_state(state, is_best)\n",
    "        \n",
    "        if exit_counter == 20:\n",
    "            print(\"Exit\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, explain):\n",
    "\n",
    "    # LOAD DATA\n",
    "    model_name = f'{args.model}_split{args.split}'\n",
    "    test_data = DysgraphiaDL(args.aug, 'test', DEVICE)\n",
    "\n",
    "    out_classes = 1\n",
    "\n",
    "    # LOAD MODEL\n",
    "    if args.model == 'vit':\n",
    "        wrapper = ViTWrapper(model_name, DEVICE, out_classes)\n",
    "    elif args.model == 'resnet':\n",
    "        wrapper = ResnetWrapper(model_name, DEVICE, out_classes, False)\n",
    "    else:\n",
    "        raise Exception(f'{model} is not a model: selecte either vit or resnet.')\n",
    "    \n",
    "    wrapper.load_state(f'{model_name}_model_best.pth')\n",
    "    model = wrapper.get_model()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loader = iter(DataLoader(test_data, batch_size=len(test_data), shuffle=False))\n",
    "        images, classes, pfeat = next(loader)\n",
    "\n",
    "        def predict(imgs, pfeat):\n",
    "            if isinstance(imgs, np.ndarray): imgs = torch.tensor(imgs).to(DEVICE)\n",
    "            preds  = model(images)\n",
    "            return preds\n",
    "        \n",
    "        out = predict(images, pfeat)\n",
    "\n",
    "    act = Sigmoid()\n",
    "    preds = torch.reshape(act(out), (-1,)).cpu()\n",
    "    classes = np.asarray(classes.cpu())\n",
    "\n",
    "    print(f\"Test Results {model_name}\")\n",
    "    print(\"---\")\n",
    "    print(\"Predictions: \", np.asarray(preds.cpu()))\n",
    "    print(\"Classes: \", classes)\n",
    "    print(\"---\")\n",
    "\n",
    "    preds_binary = (np.array(preds) >= 0.5).astype(int)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(classes, preds_binary, average='macro')\n",
    "    accuracy = accuracy_score(classes, preds_binary)\n",
    "\n",
    "    print(\"Precision:\", round(precision, 3))\n",
    "    print(\"Recall:\", round(recall, 3))\n",
    "    print(\"F1:\", round(f1, 3))\n",
    "    print(\"Accuracy:\", round(accuracy, 3))\n",
    "\n",
    "    mse = root_mean_squared_error(classes, preds)\n",
    "    print(\"Mean Squarred Error:\", round(mse, 3))\n",
    "\n",
    "    if explain:\n",
    "        topk = 2\n",
    "        batch_size = 50\n",
    "        n_evals = 10000\n",
    "        masker_blur = shap.maskers.Image(\"blur(128,128)\", images[0].shape)\n",
    "        class_names = {0: 'not-disgraphia', 1: 'disgraphia'}\n",
    "        def class_to_names(cls):\n",
    "            names = []\n",
    "            for c in cls:\n",
    "                names.append(class_names[c])\n",
    "            return names\n",
    "        explainer = shap.Explainer(predict, masker_blur, output_names=['not-disgraphia', 'disgraphia'])\n",
    "        shap_values = explainer(images[:2], max_evals=n_evals, batch_size=batch_size,\n",
    "                        outputs=shap.Explanation.argsort.flip[:topk])\n",
    "        shap_values.data = shap_values.data.cpu().numpy()[0]\n",
    "        shap_values.values = [val for val in np.moveaxis(shap_values.values,-1, 0)]\n",
    "        shap.image_plot(shap_values=shap_values.values, pixel_values=shap_values.data, \n",
    "                        labels=shap_values.output_names, true_labels=class_to_names(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(resume_iam=False, resume=False, model='resnet', aug='no_aug', split=0, freeze=False, explain=False, test=False)\n",
      "Creating Simple splits.\n",
      "Creating Simple splits.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renzi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\renzi\\AppData\\Local\\Temp\\ipykernel_18964\\751997194.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  s = torch.load(os.path.join(CHECKPOINTS, s))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=100, bias=True)\n",
      "    (1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=100, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Start Training\n",
      "Epoch 1: Train Loss 0.690743176266551 - Train Criteria 0.5019798520102522 - Time 0:00:26.365945\n",
      "Epoch 1: Validation Loss 0.6634377837181091 - Validation Criteria 0.48525163565142704\n",
      "    !- Validation improovement! inf -> 0.48525163565142704\n",
      "Epoch 2: Train Loss 0.6587949376553297 - Train Criteria 0.4867162414586541 - Time 0:00:27.276998\n",
      "Epoch 2: Validation Loss 0.6318961977958679 - Validation Criteria 0.4690071607060929\n",
      "    !- Validation improovement! 0.48525163565142704 -> 0.4690071607060929\n",
      "Epoch 3: Train Loss 0.6245785197243094 - Train Criteria 0.4684691211019954 - Time 0:00:26.446703\n",
      "Epoch 3: Validation Loss 0.6105706691741943 - Validation Criteria 0.45867832455519464\n",
      "    !- Validation improovement! 0.4690071607060929 -> 0.45867832455519464\n",
      "Epoch 4: Train Loss 0.5817779749631882 - Train Criteria 0.44539330901682195 - Time 0:00:26.462192\n",
      "Epoch 4: Validation Loss 0.5539923906326294 - Validation Criteria 0.4300766781510073\n",
      "    !- Validation improovement! 0.45867832455519464 -> 0.4300766781510073\n",
      "Epoch 5: Train Loss 0.5631997566670179 - Train Criteria 0.4352999981906763 - Time 0:00:26.428305\n",
      "Epoch 5: Validation Loss 0.5483652949333191 - Validation Criteria 0.42831431473412807\n",
      "    !- Validation improovement! 0.4300766781510073 -> 0.42831431473412807\n",
      "Epoch 6: Train Loss 0.5254959492012858 - Train Criteria 0.4184492574493935 - Time 0:00:25.864515\n",
      "Epoch 6: Validation Loss 0.5163584351539612 - Validation Criteria 0.4130527005538687\n",
      "    !- Validation improovement! 0.42831431473412807 -> 0.4130527005538687\n",
      "Epoch 7: Train Loss 0.5082045486196876 - Train Criteria 0.40289826703040993 - Time 0:00:26.117061\n",
      "Epoch 7: Validation Loss 0.5110598802566528 - Validation Criteria 0.4100211026032917\n",
      "    !- Validation improovement! 0.4130527005538687 -> 0.4100211026032917\n",
      "Epoch 8: Train Loss 0.4680154686793685 - Train Criteria 0.38615925825113767 - Time 0:00:26.095377\n",
      "Epoch 8: Validation Loss 0.4666454493999481 - Validation Criteria 0.38897301484366276\n",
      "    !- Validation improovement! 0.4100211026032917 -> 0.38897301484366276\n",
      "Epoch 9: Train Loss 0.4371737805195153 - Train Criteria 0.3679762613075743 - Time 0:00:26.016361\n",
      "Epoch 9: Validation Loss 0.48869261145591736 - Validation Criteria 0.4021040984225442\n",
      "    !- No improovement!\n",
      "Epoch 10: Train Loss 0.4193587205372751 - Train Criteria 0.3589045806542596 - Time 0:00:26.273139\n",
      "Epoch 10: Validation Loss 0.4130507707595825 - Validation Criteria 0.35890058169010064\n",
      "    !- Validation improovement! 0.38897301484366276 -> 0.35890058169010064\n",
      "Epoch 11: Train Loss 0.3894868460483849 - Train Criteria 0.33561980216106013 - Time 0:00:26.310292\n",
      "Epoch 11: Validation Loss 0.46486783027648926 - Validation Criteria 0.3903167951898496\n",
      "    !- No improovement!\n",
      "Epoch 12: Train Loss 0.3613751269876957 - Train Criteria 0.32209413475560034 - Time 0:00:26.379307\n",
      "Epoch 12: Validation Loss 0.4078916311264038 - Validation Criteria 0.3546822573378614\n",
      "    !- Validation improovement! 0.35890058169010064 -> 0.3546822573378614\n",
      "Epoch 13: Train Loss 0.34088499192148447 - Train Criteria 0.30466622618454764 - Time 0:00:27.914761\n",
      "Epoch 13: Validation Loss 0.33955490589141846 - Validation Criteria 0.3174392251476206\n",
      "    !- Validation improovement! 0.3546822573378614 -> 0.3174392251476206\n",
      "Epoch 14: Train Loss 0.32983426889404655 - Train Criteria 0.29553476556818553 - Time 0:00:23.502076\n",
      "Epoch 14: Validation Loss 0.3309396505355835 - Validation Criteria 0.3112298966670608\n",
      "    !- Validation improovement! 0.3174392251476206 -> 0.3112298966670608\n",
      "Epoch 15: Train Loss 0.3140683777164668 - Train Criteria 0.286722068256919 - Time 0:00:26.550791\n",
      "Epoch 15: Validation Loss 0.3306678533554077 - Validation Criteria 0.3120405770337917\n",
      "    !- No improovement!\n",
      "Epoch 16: Train Loss 0.2900205203332007 - Train Criteria 0.26053124556993634 - Time 0:00:26.976556\n",
      "Epoch 16: Validation Loss 0.5253491401672363 - Validation Criteria 0.4220346280951299\n",
      "    !- No improovement!\n",
      "Epoch 17: Train Loss 0.2796601152513176 - Train Criteria 0.2613900050834097 - Time 0:00:27.222476\n",
      "Epoch 17: Validation Loss 0.3357902467250824 - Validation Criteria 0.31789223075773426\n",
      "    !- No improovement!\n",
      "Epoch 18: Train Loss 0.27043727645650506 - Train Criteria 0.252684514140023 - Time 0:00:26.996727\n",
      "Epoch 18: Validation Loss 0.3753144443035126 - Validation Criteria 0.3381279985319858\n",
      "    !- No improovement!\n",
      "Epoch 19: Train Loss 0.27717676921747625 - Train Criteria 0.2612151667275656 - Time 0:00:26.934014\n",
      "Epoch 19: Validation Loss 0.35954344272613525 - Validation Criteria 0.3306252011378325\n",
      "    !- No improovement!\n",
      "Epoch 20: Train Loss 0.219445078400895 - Train Criteria 0.20923028116145104 - Time 0:00:26.871877\n",
      "Epoch 20: Validation Loss 0.2893768548965454 - Validation Criteria 0.28886963492735634\n",
      "    !- Validation improovement! 0.3112298966670608 -> 0.28886963492735634\n",
      "Epoch 21: Train Loss 0.23594852443784475 - Train Criteria 0.2287350138336997 - Time 0:00:27.154156\n",
      "Epoch 21: Validation Loss 0.18517430126667023 - Validation Criteria 0.20946189759753778\n",
      "    !- Validation improovement! 0.28886963492735634 -> 0.20946189759753778\n",
      "Epoch 22: Train Loss 0.1793507458642125 - Train Criteria 0.18524752462168495 - Time 0:00:26.928121\n",
      "Epoch 22: Validation Loss 0.24029791355133057 - Validation Criteria 0.25607815195574235\n",
      "    !- No improovement!\n",
      "Epoch 23: Train Loss 0.2188864297932014 - Train Criteria 0.1943289798155169 - Time 0:00:26.833754\n",
      "Epoch 23: Validation Loss 0.3454478979110718 - Validation Criteria 0.32318529839821747\n",
      "    !- No improovement!\n",
      "Epoch 24: Train Loss 0.22137551463674754 - Train Criteria 0.20844936587228988 - Time 0:00:26.613050\n",
      "Epoch 24: Validation Loss 0.2579347789287567 - Validation Criteria 0.2683947543940692\n",
      "    !- No improovement!\n",
      "Epoch 25: Train Loss 0.2539180436870083 - Train Criteria 0.23873506447577864 - Time 0:00:26.224753\n",
      "Epoch 25: Validation Loss 0.13928477466106415 - Validation Criteria 0.17254199330375797\n",
      "    !- Validation improovement! 0.20946189759753778 -> 0.17254199330375797\n",
      "Epoch 26: Train Loss 0.1753562850644812 - Train Criteria 0.17562718563932656 - Time 0:00:25.638635\n",
      "Epoch 26: Validation Loss 0.42632126808166504 - Validation Criteria 0.37211742594290403\n",
      "    !- No improovement!\n",
      "Epoch 27: Train Loss 0.1760835082968697 - Train Criteria 0.17916259828333492 - Time 0:00:26.762505\n",
      "Epoch 27: Validation Loss 0.25685927271842957 - Validation Criteria 0.2719671838763887\n",
      "    !- No improovement!\n",
      "Epoch 28: Train Loss 0.1406583251664415 - Train Criteria 0.13821348300838515 - Time 0:00:26.615078\n",
      "Epoch 28: Validation Loss 0.26739704608917236 - Validation Criteria 0.2826164963224838\n",
      "    !- No improovement!\n",
      "Epoch 29: Train Loss 0.15160021523479372 - Train Criteria 0.1494214658124505 - Time 0:00:25.575926\n",
      "Epoch 29: Validation Loss 0.1323404461145401 - Validation Criteria 0.17028326121917758\n",
      "    !- Validation improovement! 0.17254199330375797 -> 0.17028326121917758\n",
      "Epoch 30: Train Loss 0.1917243938660249 - Train Criteria 0.17591245704172645 - Time 0:00:26.775084\n",
      "Epoch 30: Validation Loss 0.2157292664051056 - Validation Criteria 0.23855080473089163\n",
      "    !- No improovement!\n",
      "Epoch 31: Train Loss 0.18949867563787848 - Train Criteria 0.16338360997891202 - Time 0:00:26.608502\n",
      "Epoch 31: Validation Loss 0.19042128324508667 - Validation Criteria 0.2226497178438628\n",
      "    !- No improovement!\n",
      "Epoch 32: Train Loss 0.14472401747480035 - Train Criteria 0.14029873054001807 - Time 0:00:26.997895\n",
      "Epoch 32: Validation Loss 0.13294950127601624 - Validation Criteria 0.18117870521666474\n",
      "    !- No improovement!\n",
      "Epoch 33: Train Loss 0.20482732320670038 - Train Criteria 0.17736869833639296 - Time 0:00:26.780353\n",
      "Epoch 33: Validation Loss 0.09974060207605362 - Validation Criteria 0.1371689189361818\n",
      "    !- Validation improovement! 0.17028326121917758 -> 0.1371689189361818\n",
      "Epoch 34: Train Loss 0.11478893854655325 - Train Criteria 0.12406756310517736 - Time 0:00:26.771463\n",
      "Epoch 34: Validation Loss 0.07913202047348022 - Validation Criteria 0.09267256873858713\n",
      "    !- Validation improovement! 0.1371689189361818 -> 0.09267256873858713\n",
      "Epoch 35: Train Loss 0.1578436333220452 - Train Criteria 0.1552743022002846 - Time 0:00:26.735929\n",
      "Epoch 35: Validation Loss 0.13422049582004547 - Validation Criteria 0.1796740385409204\n",
      "    !- No improovement!\n",
      "Epoch 36: Train Loss 0.1461321071255952 - Train Criteria 0.13404480223885734 - Time 0:00:26.694453\n",
      "Epoch 36: Validation Loss 0.19083498418331146 - Validation Criteria 0.23050933849419036\n",
      "    !- No improovement!\n",
      "Epoch 37: Train Loss 0.11707897938322276 - Train Criteria 0.1139080549224876 - Time 0:00:26.659151\n",
      "Epoch 37: Validation Loss 0.25247466564178467 - Validation Criteria 0.27381859261426056\n",
      "    !- No improovement!\n",
      "Epoch 38: Train Loss 0.10270919709000736 - Train Criteria 0.11406149152268194 - Time 0:00:26.642838\n",
      "Epoch 38: Validation Loss 0.34028738737106323 - Validation Criteria 0.3233891105228704\n",
      "    !- No improovement!\n",
      "Epoch 39: Train Loss 0.18027270410675555 - Train Criteria 0.1522812729470484 - Time 0:00:26.693619\n",
      "Epoch 39: Validation Loss 0.27557283639907837 - Validation Criteria 0.2882759541602439\n",
      "    !- No improovement!\n",
      "Epoch 40: Train Loss 0.12650730984751135 - Train Criteria 0.1265837818466157 - Time 0:00:26.538508\n",
      "Epoch 40: Validation Loss 0.26179441809654236 - Validation Criteria 0.2852394813267456\n",
      "    !- No improovement!\n",
      "Epoch 41: Train Loss 0.08939973940141499 - Train Criteria 0.09743582924426057 - Time 0:00:26.560480\n",
      "Epoch 41: Validation Loss 0.11357477307319641 - Validation Criteria 0.16053959596865564\n",
      "    !- No improovement!\n",
      "Epoch 42: Train Loss 0.13215741305612028 - Train Criteria 0.13145576646153756 - Time 0:00:26.817860\n",
      "Epoch 42: Validation Loss 0.07944914698600769 - Validation Criteria 0.10217128088459584\n",
      "    !- No improovement!\n",
      "Epoch 43: Train Loss 0.1589151598745957 - Train Criteria 0.14831209764533343 - Time 0:00:26.928851\n",
      "Epoch 43: Validation Loss 0.09175354242324829 - Validation Criteria 0.13305513785170697\n",
      "    !- No improovement!\n",
      "Epoch 44: Train Loss 0.08829357731156051 - Train Criteria 0.09355610782618874 - Time 0:00:26.293268\n",
      "Epoch 44: Validation Loss 0.35308870673179626 - Validation Criteria 0.33858371449117597\n",
      "    !- No improovement!\n",
      "Epoch 45: Train Loss 0.1194914395455271 - Train Criteria 0.12655715577373922 - Time 0:00:26.431378\n",
      "Epoch 45: Validation Loss 0.059234026819467545 - Validation Criteria 0.06853374878066615\n",
      "    !- Validation improovement! 0.09267256873858713 -> 0.06853374878066615\n",
      "Epoch 46: Train Loss 0.1402050934266299 - Train Criteria 0.11220249997295041 - Time 0:00:26.855717\n",
      "Epoch 46: Validation Loss 0.12637755274772644 - Validation Criteria 0.17278730477887877\n",
      "    !- No improovement!\n",
      "Epoch 47: Train Loss 0.18909643311053514 - Train Criteria 0.16668024905200785 - Time 0:00:26.778095\n",
      "Epoch 47: Validation Loss 0.38435253500938416 - Validation Criteria 0.35387814125397093\n",
      "    !- No improovement!\n",
      "Epoch 48: Train Loss 0.18652409641072154 - Train Criteria 0.1687808524476823 - Time 0:00:26.723643\n",
      "Epoch 48: Validation Loss 0.09559761732816696 - Validation Criteria 0.1372522750689548\n",
      "    !- No improovement!\n",
      "Epoch 49: Train Loss 0.11420904286205769 - Train Criteria 0.10445640437842635 - Time 0:00:27.407461\n",
      "Epoch 49: Validation Loss 0.05248858407139778 - Validation Criteria 0.06027633757979062\n",
      "    !- Validation improovement! 0.06853374878066615 -> 0.06027633757979062\n",
      "Epoch 50: Train Loss 0.11317474814131856 - Train Criteria 0.11276750173428608 - Time 0:00:28.090412\n",
      "Epoch 50: Validation Loss 0.13231423497200012 - Validation Criteria 0.17070887610847477\n",
      "    !- No improovement!\n",
      "Epoch 51: Train Loss 0.1378387470031157 - Train Criteria 0.12554767997833402 - Time 0:00:27.630712\n",
      "Epoch 51: Validation Loss 0.06600718945264816 - Validation Criteria 0.08800003998230709\n",
      "    !- No improovement!\n",
      "Epoch 52: Train Loss 0.11588121962267905 - Train Criteria 0.11429398076214718 - Time 0:00:28.136303\n",
      "Epoch 52: Validation Loss 0.09880194813013077 - Validation Criteria 0.1408637210431869\n",
      "    !- No improovement!\n",
      "Epoch 53: Train Loss 0.11748514347709715 - Train Criteria 0.11424268337709563 - Time 0:00:27.778003\n",
      "Epoch 53: Validation Loss 0.07924169301986694 - Validation Criteria 0.11987121028479053\n",
      "    !- No improovement!\n",
      "Epoch 54: Train Loss 0.11775124724954367 - Train Criteria 0.10004383767003033 - Time 0:00:27.804224\n",
      "Epoch 54: Validation Loss 0.14424799382686615 - Validation Criteria 0.18602439161529888\n",
      "    !- No improovement!\n",
      "Epoch 55: Train Loss 0.0881493795895949 - Train Criteria 0.08793736187828885 - Time 0:00:27.973447\n",
      "Epoch 55: Validation Loss 0.09701749682426453 - Validation Criteria 0.13853837548524842\n",
      "    !- No improovement!\n",
      "Epoch 56: Train Loss 0.13334623526316136 - Train Criteria 0.11678352501591417 - Time 0:00:28.062998\n",
      "Epoch 56: Validation Loss 0.09928670525550842 - Validation Criteria 0.1456411318669209\n",
      "    !- No improovement!\n",
      "Epoch 57: Train Loss 0.08309827343327925 - Train Criteria 0.08125938034267627 - Time 0:00:28.416079\n",
      "Epoch 57: Validation Loss 0.1601877361536026 - Validation Criteria 0.20524456528926124\n",
      "    !- No improovement!\n",
      "Epoch 58: Train Loss 0.1032703536329791 - Train Criteria 0.10100884003640365 - Time 0:00:27.970412\n",
      "Epoch 58: Validation Loss 0.08695138245820999 - Validation Criteria 0.1349153156782387\n",
      "    !- No improovement!\n",
      "Epoch 59: Train Loss 0.10411737964022905 - Train Criteria 0.08747369471693422 - Time 0:00:28.218644\n",
      "Epoch 59: Validation Loss 0.05392327904701233 - Validation Criteria 0.07574507510909122\n",
      "    !- No improovement!\n",
      "Epoch 60: Train Loss 0.06708411127328873 - Train Criteria 0.06597330845034251 - Time 0:00:27.832216\n",
      "Epoch 60: Validation Loss 0.07360249012708664 - Validation Criteria 0.12062220244240687\n",
      "    !- No improovement!\n",
      "Epoch 61: Train Loss 0.059377495548687875 - Train Criteria 0.060028841942457306 - Time 0:00:27.732766\n",
      "Epoch 61: Validation Loss 0.045589495450258255 - Validation Criteria 0.04940264659940427\n",
      "    !- Validation improovement! 0.06027633757979062 -> 0.04940264659940427\n",
      "Epoch 62: Train Loss 0.06691589730326086 - Train Criteria 0.07121204690088201 - Time 0:00:27.482632\n",
      "Epoch 62: Validation Loss 0.04837247356772423 - Validation Criteria 0.054400654149068604\n",
      "    !- No improovement!\n",
      "Epoch 63: Train Loss 0.10019311076030135 - Train Criteria 0.09636906290758342 - Time 0:00:27.511770\n",
      "Epoch 63: Validation Loss 0.33133915066719055 - Validation Criteria 0.31083391130733706\n",
      "    !- No improovement!\n",
      "Epoch 64: Train Loss 0.13990032498259097 - Train Criteria 0.12773156249504963 - Time 0:00:27.997001\n",
      "Epoch 64: Validation Loss 0.11867499351501465 - Validation Criteria 0.173555217583308\n",
      "    !- No improovement!\n",
      "Epoch 65: Train Loss 0.15768622496398166 - Train Criteria 0.12834756586775864 - Time 0:00:27.841368\n",
      "Epoch 65: Validation Loss 0.1553967297077179 - Validation Criteria 0.20446935901273944\n",
      "    !- No improovement!\n",
      "Epoch 66: Train Loss 0.061555686173960567 - Train Criteria 0.06367142336276571 - Time 0:00:27.417737\n",
      "Epoch 66: Validation Loss 0.31459859013557434 - Validation Criteria 0.3129070376059988\n",
      "    !- No improovement!\n",
      "Epoch 67: Train Loss 0.06948548892978579 - Train Criteria 0.07350085952604724 - Time 0:00:28.264629\n",
      "Epoch 67: Validation Loss 0.06769657135009766 - Validation Criteria 0.10133822332870972\n",
      "    !- No improovement!\n",
      "Epoch 68: Train Loss 0.0644967082189396 - Train Criteria 0.06725147796408631 - Time 0:00:28.376603\n",
      "Epoch 68: Validation Loss 0.04348772019147873 - Validation Criteria 0.04570531485549289\n",
      "    !- Validation improovement! 0.04940264659940427 -> 0.04570531485549289\n",
      "Epoch 69: Train Loss 0.06369824893772602 - Train Criteria 0.06364976162916995 - Time 0:00:27.913557\n",
      "Epoch 69: Validation Loss 0.05642698332667351 - Validation Criteria 0.08810453996039817\n",
      "    !- No improovement!\n",
      "Epoch 70: Train Loss 0.07577319128904492 - Train Criteria 0.073198594891205 - Time 0:00:27.745471\n",
      "Epoch 70: Validation Loss 0.2588694989681244 - Validation Criteria 0.28630548686995055\n",
      "    !- No improovement!\n",
      "Epoch 71: Train Loss 0.09169870265759528 - Train Criteria 0.0965962235958313 - Time 0:00:27.760231\n",
      "Epoch 71: Validation Loss 0.05113690719008446 - Validation Criteria 0.07546022145124118\n",
      "    !- No improovement!\n",
      "Epoch 72: Train Loss 0.05633578315610066 - Train Criteria 0.05607962087780661 - Time 0:00:27.782341\n",
      "Epoch 72: Validation Loss 0.12004143744707108 - Validation Criteria 0.17059657462194722\n",
      "    !- No improovement!\n",
      "Epoch 73: Train Loss 0.0550189251662232 - Train Criteria 0.058813651566676534 - Time 0:00:27.785365\n",
      "Epoch 73: Validation Loss 0.04504099860787392 - Validation Criteria 0.053291205798347244\n",
      "    !- No improovement!\n",
      "Epoch 74: Train Loss 0.0930602898588404 - Train Criteria 0.07405985044724653 - Time 0:00:27.732398\n",
      "Epoch 74: Validation Loss 0.2259000688791275 - Validation Criteria 0.25668649052369163\n",
      "    !- No improovement!\n",
      "Epoch 75: Train Loss 0.08905904949642718 - Train Criteria 0.08699089223209276 - Time 0:00:27.599120\n",
      "Epoch 75: Validation Loss 0.05945737287402153 - Validation Criteria 0.09847460664842993\n",
      "    !- No improovement!\n",
      "Epoch 76: Train Loss 0.14030557684600353 - Train Criteria 0.12074514363783116 - Time 0:00:27.643044\n",
      "Epoch 76: Validation Loss 0.06669087707996368 - Validation Criteria 0.09476021006002658\n",
      "    !- No improovement!\n",
      "Epoch 77: Train Loss 0.12420565728098154 - Train Criteria 0.10419653413191525 - Time 0:00:27.624990\n",
      "Epoch 77: Validation Loss 0.07868265360593796 - Validation Criteria 0.12451443336096081\n",
      "    !- No improovement!\n",
      "Epoch 78: Train Loss 0.13646718603558838 - Train Criteria 0.10782071750660994 - Time 0:00:27.559593\n",
      "Epoch 78: Validation Loss 0.03919411450624466 - Validation Criteria 0.0414880444907295\n",
      "    !- Validation improovement! 0.04570531485549289 -> 0.0414880444907295\n",
      "Epoch 79: Train Loss 0.062499871535692364 - Train Criteria 0.06851699063762706 - Time 0:00:27.775346\n",
      "Epoch 79: Validation Loss 0.09581569582223892 - Validation Criteria 0.14686126931947147\n",
      "    !- No improovement!\n",
      "Epoch 80: Train Loss 0.09949891059659421 - Train Criteria 0.08660133313408552 - Time 0:00:27.790250\n",
      "Epoch 80: Validation Loss 0.03716566786170006 - Validation Criteria 0.03725989924502455\n",
      "    !- Validation improovement! 0.0414880444907295 -> 0.03725989924502455\n",
      "Epoch 81: Train Loss 0.09407400048803538 - Train Criteria 0.08780758698805582 - Time 0:00:27.638106\n",
      "Epoch 81: Validation Loss 0.10009270906448364 - Validation Criteria 0.1511844721858624\n",
      "    !- No improovement!\n",
      "Epoch 82: Train Loss 0.0594434961094521 - Train Criteria 0.06170862890226691 - Time 0:00:27.706475\n",
      "Epoch 82: Validation Loss 0.30022338032722473 - Validation Criteria 0.2993638831091183\n",
      "    !- No improovement!\n",
      "Epoch 83: Train Loss 0.09002993785543367 - Train Criteria 0.08569138346206871 - Time 0:00:28.106283\n",
      "Epoch 83: Validation Loss 0.038377173244953156 - Validation Criteria 0.0413655745052645\n",
      "    !- No improovement!\n",
      "Epoch 84: Train Loss 0.0884179852437228 - Train Criteria 0.07955484225627119 - Time 0:00:27.973245\n",
      "Epoch 84: Validation Loss 0.07805433869361877 - Validation Criteria 0.1274688966273782\n",
      "    !- No improovement!\n",
      "Epoch 85: Train Loss 0.05109963921131566 - Train Criteria 0.05425196060299004 - Time 0:00:27.832872\n",
      "Epoch 85: Validation Loss 0.0885227769613266 - Validation Criteria 0.13518119786529123\n",
      "    !- No improovement!\n",
      "Epoch 86: Train Loss 0.08996120427036658 - Train Criteria 0.0849044794133256 - Time 0:00:27.610241\n",
      "Epoch 86: Validation Loss 0.069636769592762 - Validation Criteria 0.11773161507076647\n",
      "    !- No improovement!\n",
      "Epoch 87: Train Loss 0.08716667810222134 - Train Criteria 0.08027245194711137 - Time 0:00:27.680897\n",
      "Epoch 87: Validation Loss 0.06921908259391785 - Validation Criteria 0.11772884370035605\n",
      "    !- No improovement!\n",
      "Epoch 88: Train Loss 0.05623133375775069 - Train Criteria 0.05600572795344024 - Time 0:00:27.743186\n",
      "Epoch 88: Validation Loss 0.03718405216932297 - Validation Criteria 0.037918135279795595\n",
      "    !- No improovement!\n",
      "Epoch 89: Train Loss 0.07968441880075261 - Train Criteria 0.07530915996918815 - Time 0:00:27.612327\n",
      "Epoch 89: Validation Loss 0.13067959249019623 - Validation Criteria 0.18009081094947463\n",
      "    !- No improovement!\n",
      "Epoch 90: Train Loss 0.08615560061298311 - Train Criteria 0.08237765142811165 - Time 0:00:27.705438\n",
      "Epoch 90: Validation Loss 0.035530876368284225 - Validation Criteria 0.03590077744654411\n",
      "    !- Validation improovement! 0.03725989924502455 -> 0.03590077744654411\n",
      "Epoch 91: Train Loss 0.06108569243224338 - Train Criteria 0.06711504150968613 - Time 0:00:27.774904\n",
      "Epoch 91: Validation Loss 0.16850195825099945 - Validation Criteria 0.21773311827961603\n",
      "    !- No improovement!\n",
      "Epoch 92: Train Loss 0.10219942883122712 - Train Criteria 0.081627263498101 - Time 0:00:27.301139\n",
      "Epoch 92: Validation Loss 0.0747900977730751 - Validation Criteria 0.12213001462523927\n",
      "    !- No improovement!\n",
      "Epoch 93: Train Loss 0.04817352193640545 - Train Criteria 0.05054253950769824 - Time 0:00:27.371805\n",
      "Epoch 93: Validation Loss 0.036470863968133926 - Validation Criteria 0.038075496544194634\n",
      "    !- No improovement!\n",
      "Epoch 94: Train Loss 0.07415602548280731 - Train Criteria 0.07627413596367925 - Time 0:00:27.333319\n",
      "Epoch 94: Validation Loss 0.043005093932151794 - Validation Criteria 0.0609591051060104\n",
      "    !- No improovement!\n",
      "Epoch 95: Train Loss 0.05928902165032923 - Train Criteria 0.05823834559226094 - Time 0:00:27.415838\n",
      "Epoch 95: Validation Loss 0.09614866971969604 - Validation Criteria 0.14493018335735922\n",
      "    !- No improovement!\n",
      "Epoch 96: Train Loss 0.05600467085605487 - Train Criteria 0.0557196008535633 - Time 0:00:27.344599\n",
      "Epoch 96: Validation Loss 0.09727790951728821 - Validation Criteria 0.1525349235763837\n",
      "    !- No improovement!\n",
      "Epoch 97: Train Loss 0.054300078307278454 - Train Criteria 0.054471002490479495 - Time 0:00:27.499186\n",
      "Epoch 97: Validation Loss 0.04044804722070694 - Validation Criteria 0.04672047196695805\n",
      "    !- No improovement!\n",
      "Epoch 98: Train Loss 0.04423030203906819 - Train Criteria 0.04581924977398834 - Time 0:00:27.362998\n",
      "Epoch 98: Validation Loss 0.05118406191468239 - Validation Criteria 0.07888584734369192\n",
      "    !- No improovement!\n",
      "Epoch 99: Train Loss 0.07428096618968993 - Train Criteria 0.07635273646611698 - Time 0:00:27.335914\n",
      "Epoch 99: Validation Loss 0.039116937667131424 - Validation Criteria 0.0467585801906669\n",
      "    !- No improovement!\n",
      "Epoch 100: Train Loss 0.07062946038786322 - Train Criteria 0.07177483899680107 - Time 0:00:27.436635\n",
      "Epoch 100: Validation Loss 0.03527819737792015 - Validation Criteria 0.03536179785096817\n",
      "    !- No improovement!\n",
      "Epoch 101: Train Loss 0.08434567134827375 - Train Criteria 0.07819822041889499 - Time 0:00:27.395298\n",
      "Epoch 101: Validation Loss 0.045650191605091095 - Validation Criteria 0.0706327110146866\n",
      "    !- No improovement!\n",
      "Epoch 102: Train Loss 0.11650856246706098 - Train Criteria 0.09937118060602068 - Time 0:00:27.391755\n",
      "Epoch 102: Validation Loss 0.07217102497816086 - Validation Criteria 0.12455764836380116\n",
      "    !- No improovement!\n",
      "Epoch 103: Train Loss 0.07803821912966669 - Train Criteria 0.079532969551541 - Time 0:00:27.550138\n",
      "Epoch 103: Validation Loss 0.08071345835924149 - Validation Criteria 0.14123170356085862\n",
      "    !- No improovement!\n",
      "Epoch 104: Train Loss 0.09308882727054879 - Train Criteria 0.07265695251861926 - Time 0:00:27.628287\n",
      "Epoch 104: Validation Loss 0.07576712220907211 - Validation Criteria 0.1272658189074481\n",
      "    !- No improovement!\n",
      "Epoch 105: Train Loss 0.060650441446341574 - Train Criteria 0.05768546371523766 - Time 0:00:27.500208\n",
      "Epoch 105: Validation Loss 0.03229342773556709 - Validation Criteria 0.03234762588231491\n",
      "    !- Validation improovement! 0.03590077744654411 -> 0.03234762588231491\n",
      "Epoch 106: Train Loss 0.11052399774780497 - Train Criteria 0.087707237924646 - Time 0:00:27.627284\n",
      "Epoch 106: Validation Loss 0.1369408667087555 - Validation Criteria 0.1934484513227222\n",
      "    !- No improovement!\n",
      "Epoch 107: Train Loss 0.051069371576886624 - Train Criteria 0.057701401570839486 - Time 0:00:28.394778\n",
      "Epoch 107: Validation Loss 0.04407859221100807 - Validation Criteria 0.07186393923153495\n",
      "    !- No improovement!\n",
      "Epoch 108: Train Loss 0.07818115962436423 - Train Criteria 0.0749122028885185 - Time 0:00:27.712093\n",
      "Epoch 108: Validation Loss 0.044432852417230606 - Validation Criteria 0.0768059509421241\n",
      "    !- No improovement!\n",
      "Epoch 109: Train Loss 0.057023243862204254 - Train Criteria 0.05993635594858878 - Time 0:00:27.564011\n",
      "Epoch 109: Validation Loss 0.044571179896593094 - Validation Criteria 0.06792731010218099\n",
      "    !- No improovement!\n",
      "Epoch 110: Train Loss 0.06204141501802951 - Train Criteria 0.06246244898232607 - Time 0:00:27.707198\n",
      "Epoch 110: Validation Loss 0.040185850113630295 - Validation Criteria 0.05507733146792391\n",
      "    !- No improovement!\n",
      "Epoch 111: Train Loss 0.09250769030768424 - Train Criteria 0.07626757888272881 - Time 0:00:27.808916\n",
      "Epoch 111: Validation Loss 0.060421571135520935 - Validation Criteria 0.10427597861287322\n",
      "    !- No improovement!\n",
      "Epoch 112: Train Loss 0.06303160241805017 - Train Criteria 0.06629896765725288 - Time 0:00:27.635932\n",
      "Epoch 112: Validation Loss 0.08042711019515991 - Validation Criteria 0.13017924688458782\n",
      "    !- No improovement!\n",
      "Epoch 113: Train Loss 0.051343321276362985 - Train Criteria 0.049116763309730235 - Time 0:00:27.688434\n",
      "Epoch 113: Validation Loss 0.08377928286790848 - Validation Criteria 0.13094613227775534\n",
      "    !- No improovement!\n",
      "Epoch 114: Train Loss 0.06497886450961232 - Train Criteria 0.060662652611801 - Time 0:00:27.630212\n",
      "Epoch 114: Validation Loss 0.07684192806482315 - Validation Criteria 0.12880834652709192\n",
      "    !- No improovement!\n",
      "Epoch 115: Train Loss 0.06527861679205671 - Train Criteria 0.06405713462737753 - Time 0:00:27.720042\n",
      "Epoch 115: Validation Loss 0.11913920938968658 - Validation Criteria 0.15440383431945137\n",
      "    !- No improovement!\n",
      "Epoch 116: Train Loss 0.06388069113017991 - Train Criteria 0.06454781560400691 - Time 0:00:27.694918\n",
      "Epoch 116: Validation Loss 0.032082680612802505 - Validation Criteria 0.03261628873461049\n",
      "    !- No improovement!\n",
      "Epoch 117: Train Loss 0.04839848290430382 - Train Criteria 0.05442089211407585 - Time 0:00:27.710064\n",
      "Epoch 117: Validation Loss 0.05360094830393791 - Validation Criteria 0.1023876779166736\n",
      "    !- No improovement!\n",
      "Epoch 118: Train Loss 0.06465213949559256 - Train Criteria 0.05619846532522963 - Time 0:00:27.737689\n",
      "Epoch 118: Validation Loss 0.11493021994829178 - Validation Criteria 0.17059795038540462\n",
      "    !- No improovement!\n",
      "Epoch 119: Train Loss 0.06500039936508983 - Train Criteria 0.05819775224780107 - Time 0:00:27.653288\n",
      "Epoch 119: Validation Loss 0.03319626301527023 - Validation Criteria 0.03895770926150595\n",
      "    !- No improovement!\n",
      "Epoch 120: Train Loss 0.06616080086678267 - Train Criteria 0.05755065339904236 - Time 0:00:27.678606\n",
      "Epoch 120: Validation Loss 0.11440517008304596 - Validation Criteria 0.17446178414030414\n",
      "    !- No improovement!\n",
      "Epoch 121: Train Loss 0.0525920411455445 - Train Criteria 0.05440925441391647 - Time 0:00:27.599972\n",
      "Epoch 121: Validation Loss 0.05176728591322899 - Validation Criteria 0.09584317230630214\n",
      "    !- No improovement!\n",
      "Epoch 122: Train Loss 0.06344204663764685 - Train Criteria 0.07032705708904709 - Time 0:00:27.631036\n",
      "Epoch 122: Validation Loss 0.07188411802053452 - Validation Criteria 0.1255970710556724\n",
      "    !- No improovement!\n",
      "Epoch 123: Train Loss 0.1002959863981232 - Train Criteria 0.08810133561557734 - Time 0:00:27.590415\n",
      "Epoch 123: Validation Loss 0.045794930309057236 - Validation Criteria 0.08417007268165548\n",
      "    !- No improovement!\n",
      "Epoch 124: Train Loss 0.10692384996218607 - Train Criteria 0.0797276005334376 - Time 0:00:27.622807\n",
      "Epoch 124: Validation Loss 0.031197991222143173 - Validation Criteria 0.03212181388171819\n",
      "    !- No improovement!\n",
      "Epoch 125: Train Loss 0.08063754078466445 - Train Criteria 0.0700983547813839 - Time 0:00:27.814621\n",
      "Epoch 125: Validation Loss 0.10122920572757721 - Validation Criteria 0.15336603723550638\n",
      "    !- No improovement!\n",
      "Exit\n",
      "Creating Simple splits.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renzi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\renzi\\AppData\\Local\\Temp\\ipykernel_18964\\751997194.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  s = torch.load(os.path.join(CHECKPOINTS, s))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results resnet_split0\n",
      "---\n",
      "Predictions:  [0.03590262 0.97330755 0.03804267 0.97476643 0.97411555 0.03460326\n",
      " 0.97213364 0.0344178  0.9746115  0.97559536 0.03494362 0.974329\n",
      " 0.03518103 0.03516586 0.9742742  0.97449696 0.9749214  0.97524536\n",
      " 0.03550141 0.03472495 0.03568916 0.9738791  0.03499717 0.03555688\n",
      " 0.03572237 0.03439691 0.03512254 0.9739325  0.03536583 0.03451357\n",
      " 0.9737384  0.9742313  0.03587911 0.9750426  0.9740356  0.9659918\n",
      " 0.03506077 0.974162   0.03484368 0.03556555 0.97562975 0.04542623\n",
      " 0.9730833  0.03512604 0.03525349 0.03523761 0.973623   0.03551083\n",
      " 0.9747146  0.03494941 0.03538159 0.9740967  0.8967888  0.03503603\n",
      " 0.9736746  0.04709759 0.03571585 0.03481562]\n",
      "Classes:  [0 1 0 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 1 1 0\n",
      " 1 0 0 1 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 0 0]\n",
      "---\n",
      "Precision: 0.984\n",
      "Recall: 0.981\n",
      "F1: 0.983\n",
      "Accuracy: 0.983\n",
      "Mean Squarred Error: 0.131\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Training')\n",
    "    parser.add_argument('--resume_iam', '-ri', action=\"store_true\",\n",
    "                        help=\"resume training\")\n",
    "    parser.add_argument('--resume', '-r', action=\"store_true\",\n",
    "                        help=\"resume training with no_augmented dataset\")\n",
    "    parser.add_argument('--model', '-m', choices=['resnet18', 'vit'], default='resnet',\n",
    "                        help=\"set which model to use / train, either 'resnet' or 'vit'\")\n",
    "    parser.add_argument('--aug', '-a', choices=['aug', 'no_aug'], default='aug',\n",
    "                        help=\"set which dataset to use, either 'augmented' or 'no_augmented'\")\n",
    "    parser.add_argument('--split', '-s', default=0,\n",
    "                        help=\"which train/val/test split to load\")\n",
    "    parser.add_argument('--freeze', '-brr', action=\"store_true\",\n",
    "                        help=\"freeze all layers for training but the head\")\n",
    "    parser.add_argument('--explain', '-ex', action=\"store_true\",\n",
    "                        help=\"print explainer SHAP results\")     \n",
    "    parser.add_argument('--test', '-t', action=\"store_true\",\n",
    "                        help=\"only testing mode\")                \n",
    "\n",
    "    args = parser.parse_args([])\n",
    "    print(args)\n",
    "\n",
    "    if not args.test: \n",
    "        train(args)\n",
    "    test(args, explain=args.explain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
