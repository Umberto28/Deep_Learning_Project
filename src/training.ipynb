{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Funzioni utili**\n",
    "Definiamo alcune funzioni per la suddivisione ed il calcolo di alcune statistiche dei dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, root_mean_squared_error\n",
    "import shap\n",
    "from torch.nn import Sigmoid, BCELoss\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from math import inf\n",
    "from datetime import timedelta\n",
    "from mlxtend.evaluate import accuracy_score\n",
    "%run path.ipynb\n",
    "%run model.ipynb\n",
    "%run data.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "\n",
    "    # LOAD DATA\n",
    "    model_name = f'{args.model}_train'\n",
    " \n",
    "    train_data = DysgraphiaDL(args.aug, 'train', DEVICE)\n",
    "    validation_data = DysgraphiaDL(args.aug, 'val', DEVICE)\n",
    "    \n",
    "    # LOAD MODEL\n",
    "    if args.model == 'vit':\n",
    "        wrapper = ViTWrapper(model_name, DEVICE, 2, False)\n",
    "    elif args.model == 'resnet18':\n",
    "        wrapper = ResnetWrapper(model_name, DEVICE, 2, False)\n",
    "    else:\n",
    "        raise Exception(f'{args.model} is not a model: selecte either vit or resnet18.')\n",
    "    \n",
    "    wrapper.binary()\n",
    "    if args.freeze: wrapper.freeze()\n",
    "    model = wrapper.get_model()\n",
    "\n",
    "    print(model)\n",
    "\n",
    "    # TRAIN SETTINGS\n",
    "    epochs = 150\n",
    "    start_epoch = 0\n",
    "    batch_size = 16\n",
    "    best_val_loss = inf\n",
    "    best_val_crit = inf\n",
    "    exit_counter = 0\n",
    "    epsilon = 0.0001\n",
    "    lr = 0.00001\n",
    "\n",
    "    act = Sigmoid()\n",
    "    func = BCELoss()\n",
    "    loss = lambda x, y: func(torch.reshape(act(x), (-1,)), y.type(torch.float32))\n",
    "\n",
    "    opt = optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    if args.resume_iam:\n",
    "        start_epoch, best_val_loss, exit_counter, opt_chk, best_val_crit = wrapper.resume(f'{model_name}_checkpoint.pth')\n",
    "        opt.load_state_dict(opt_chk)\n",
    "\n",
    "    if args.resume:\n",
    "        start_epoch, best_val_loss, exit_counter, opt_chk, best_val_crit = wrapper.resume(f'{args.model}_checkpoint.pth')\n",
    "        opt.load_state_dict(opt_chk)\n",
    "\n",
    "    print('Start Training')\n",
    "    for e in range(start_epoch, epochs):\n",
    "\n",
    "        # TRAIN\n",
    "        model.train()\n",
    "        loader = iter(DataLoader(train_data, batch_size=batch_size, shuffle=True))\n",
    "        train_loss = 0.0\n",
    "        running_loss = 0.0\n",
    "        train_crit = 0.0\n",
    "        running_crit = 0.0\n",
    "\n",
    "        start = time.time()\n",
    "        for i in range(0, int(len(train_data) / batch_size) + 1):\n",
    "            images, classes, pfeat = next(loader)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            preds = model(images)\n",
    "\n",
    "            out = loss(preds, classes)\n",
    "            out.backward()\n",
    "            opt.step()\n",
    "\n",
    "            train_loss += out.item()\n",
    "            running_loss += out.item()\n",
    "\n",
    "            classes = np.asarray(classes.cpu())\n",
    "\n",
    "            preds = torch.reshape(act(preds), (-1,)).cpu().detach().numpy()\n",
    "            crit = root_mean_squared_error(classes, preds)\n",
    "            train_crit += crit\n",
    "            running_crit += crit\n",
    "\n",
    "            if i % 5 == 4:\n",
    "                print(f'Epoch {e + 1} - Batch {i + 1}: Running Loss {running_loss / 5} / Running Criteria {running_crit / 5}', end='\\r')\n",
    "                running_loss = 0.0\n",
    "                running_crit = 0.0\n",
    "        \n",
    "        train_loss = train_loss / i\n",
    "        train_crit = train_crit / i\n",
    "        print(f'Epoch {e + 1}: Train Loss {train_loss} - Train Criteria {train_crit} - Time {str(timedelta(seconds=time.time() - start))}')\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loader = iter(DataLoader(validation_data, batch_size=len(validation_data), shuffle=False))\n",
    "            images, classes, pfeat = next(loader)\n",
    "            preds  = model(images)\n",
    "            out = loss(preds, classes)\n",
    "            \n",
    "            classes = np.asarray(classes.cpu())\n",
    "           \n",
    "            preds = torch.reshape(act(preds), (-1,)).cpu()\n",
    "            crit = root_mean_squared_error(classes, preds)\n",
    "\n",
    "            val_crit = crit\n",
    "            print(f\"Epoch {e + 1}: Validation Loss {out.item()} - Validation Criteria {val_crit}\")\n",
    "            if val_crit < best_val_crit - epsilon:\n",
    "                print(f\"    !- Validation improovement! {best_val_crit} -> {val_crit}\")\n",
    "                exit_counter = 0\n",
    "                best_val_crit = val_crit\n",
    "                is_best = True\n",
    "            else:\n",
    "                print(f\"    !- No improovement!\")\n",
    "                is_best = False\n",
    "                exit_counter += 1\n",
    "            \n",
    "            state = {\n",
    "                'epoch': e + 1,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'exit_counter': exit_counter,\n",
    "                'optimizer': opt.state_dict(),\n",
    "                'best_val_crit': best_val_crit\n",
    "            }\n",
    "            wrapper.save_state(state, is_best)\n",
    "        \n",
    "        if exit_counter == 20:\n",
    "            print(\"Exit\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, explain):\n",
    "\n",
    "    # LOAD DATA\n",
    "    model_name = f'{args.model}_train'\n",
    "    test_data = DysgraphiaDL(args.aug, 'test', DEVICE)\n",
    "\n",
    "    out_classes = 1\n",
    "\n",
    "    # LOAD MODEL\n",
    "    if args.model == 'vit':\n",
    "        wrapper = ViTWrapper(model_name, DEVICE, out_classes)\n",
    "    elif args.model == 'resnet18':\n",
    "        wrapper = ResnetWrapper(model_name, DEVICE, out_classes, False)\n",
    "    else:\n",
    "        raise Exception(f'{args.model} is not a model: selecte either vit or resnet18.')\n",
    "    \n",
    "    wrapper.load_state(f'{model_name}_model_best.pth')\n",
    "    model = wrapper.get_model()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loader = iter(DataLoader(test_data, batch_size=len(test_data), shuffle=False))\n",
    "        images, classes, pfeat = next(loader)\n",
    "\n",
    "        def predict(imgs, pfeat):\n",
    "            if isinstance(imgs, np.ndarray): imgs = torch.tensor(imgs).to(DEVICE)\n",
    "            preds  = model(images)\n",
    "            return preds\n",
    "        \n",
    "        out = predict(images, pfeat)\n",
    "\n",
    "    act = Sigmoid()\n",
    "    preds = torch.reshape(act(out), (-1,)).cpu()\n",
    "    classes = np.asarray(classes.cpu())\n",
    "\n",
    "    print(f\"Test Results {model_name}\")\n",
    "    print(\"---\")\n",
    "    print(\"Predictions: \", np.asarray(preds.cpu()))\n",
    "    print(\"Classes: \", classes)\n",
    "    print(\"---\")\n",
    "\n",
    "    preds_binary = (np.array(preds) >= 0.5).astype(int)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(classes, preds_binary, average='macro')\n",
    "    accuracy = accuracy_score(classes, preds_binary)\n",
    "\n",
    "    print(\"Precision:\", round(precision, 3))\n",
    "    print(\"Recall:\", round(recall, 3))\n",
    "    print(\"F1:\", round(f1, 3))\n",
    "    print(\"Accuracy:\", round(accuracy, 3))\n",
    "\n",
    "    mse = root_mean_squared_error(classes, preds)\n",
    "    print(\"Mean Squarred Error:\", round(mse, 3))\n",
    "\n",
    "    if explain:\n",
    "        topk = 2\n",
    "        batch_size = 50\n",
    "        n_evals = 10000\n",
    "        masker_blur = shap.maskers.Image(\"blur(128,128)\", images[0].shape)\n",
    "        class_names = {0: 'not-disgraphia', 1: 'disgraphia'}\n",
    "        def class_to_names(cls):\n",
    "            names = []\n",
    "            for c in cls:\n",
    "                names.append(class_names[c])\n",
    "            return names\n",
    "        explainer = shap.Explainer(predict, masker_blur, output_names=['not-disgraphia', 'disgraphia'])\n",
    "        shap_values = explainer(images[:2], max_evals=n_evals, batch_size=batch_size,\n",
    "                        outputs=shap.Explanation.argsort.flip[:topk])\n",
    "        shap_values.data = shap_values.data.cpu().numpy()[0]\n",
    "        shap_values.values = [val for val in np.moveaxis(shap_values.values,-1, 0)]\n",
    "        shap.image_plot(shap_values=shap_values.values, pixel_values=shap_values.data, \n",
    "                        labels=shap_values.output_names, true_labels=class_to_names(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Training')\n",
    "    parser.add_argument('--resume_iam', '-ri', action=\"store_true\",\n",
    "                        help=\"resume training\")\n",
    "    parser.add_argument('--resume', '-r', action=\"store_true\",\n",
    "                        help=\"resume training with no_augmented dataset\")\n",
    "    parser.add_argument('--model', '-m', choices=['resnet18', 'vit'], default='resnet18',\n",
    "                        help=\"set which model to use / train, either 'resnet18' or 'vit'\")\n",
    "    parser.add_argument('--aug', '-a', choices=['aug', 'no_aug'], default='no_aug',\n",
    "                        help=\"set which dataset to use, either 'augmented' or 'no_augmented'\")\n",
    "    parser.add_argument('--split', '-s', default=0,\n",
    "                        help=\"which train/val/test split to load\")\n",
    "    parser.add_argument('--freeze', '-brr', action=\"store_true\",\n",
    "                        help=\"freeze all layers for training but the head\")\n",
    "    parser.add_argument('--explain', '-ex', action=\"store_true\",\n",
    "                        help=\"print explainer SHAP results\")     \n",
    "    parser.add_argument('--test', '-t', action=\"store_true\",\n",
    "                        help=\"only testing mode\")                \n",
    "\n",
    "    args = parser.parse_args([])\n",
    "    print(args)\n",
    "\n",
    "    if not args.test: \n",
    "        train(args)\n",
    "    test(args, explain=args.explain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
