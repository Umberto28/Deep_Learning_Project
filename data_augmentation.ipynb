{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1EG0wzXcCqiyBaUROehW_TOaSptQlzt83",
      "authorship_tag": "ABX9TyOFOOmWQVKlsfyDeubMjB3q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Umberto28/Deep_Learning_Project/blob/main/data_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVSt31dMnt3Z",
        "outputId": "d8622389-72b3-4054-9bd2-f4f4ffdbc7f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135 /content/drive/MyDrive/datasetLabel/NoAugmentation/No_Dysgraphic2/Copia di LPD (9).jpg\n",
            "135\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "F = ['png', 'jpg']\n",
        "D = ['Dysgraphic1', 'No_Dysgraphic1', 'Dysgraphic2', 'No_Dysgraphic2']\n",
        "\n",
        "input_folder_path = f'/content/drive/MyDrive/datasetLabel/NoAugmentation/{D[3]}'\n",
        "output_folder_path = f'/content/drive/MyDrive/datasetLabel/Augmentation/{D[3]}'\n",
        "\n",
        "file_paths = [os.path.join(input_folder_path, f) for f in os.listdir(input_folder_path) if f.endswith(f'.{F[1]}')]\n",
        "images = [tf.image.decode_image(tf.io.read_file(fp)) for fp in file_paths]\n",
        "\n",
        "augmented = []\n",
        "\n",
        "print(str(len(file_paths)) + ' ' + file_paths[0])\n",
        "print(len(images))\n",
        "print(len(augmented))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_augmentation(original_images, augmented_images):\n",
        "  for image in original_images:\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    # Get the dimensions of the image\n",
        "    shape = tf.shape(image)\n",
        "    height = tf.cast(shape[0], tf.float32)\n",
        "    width = tf.cast(shape[1], tf.float32)\n",
        "    # Calculate the size of the crop dynamically\n",
        "    crop_height = tf.cast(height * 0.8, tf.int32)\n",
        "    crop_width = tf.cast(width * 0.8, tf.int32)\n",
        "    for i in range(3):\n",
        "      seed = (i, 0)  # tuple of size (2,)\n",
        "      random_crop = tf.image.stateless_random_crop(\n",
        "          image, size=[crop_height, crop_width, 1], seed=seed)\n",
        "      augmented_images.append(random_crop)\n",
        "\n",
        "  print(len(augmented_images))\n",
        "  plt.imshow(augmented_images[0])\n",
        "  plt.show()\n",
        "\n",
        "  for i, img in enumerate(augmented_images):\n",
        "      image_data = tf.cast(img * 255, tf.uint8)\n",
        "      numpy_image = image_data.numpy()\n",
        "      rgb_image = cv2.cvtColor(numpy_image, cv2.COLOR_BGR2RGB)\n",
        "      pil_image = Image.fromarray(rgb_image)\n",
        "      pil_image.save(os.path.join(output_folder_path, f'crop_{i}.png'))\n",
        "\n",
        "augmented = []\n",
        "crop_augmentation(images, augmented)"
      ],
      "metadata": {
        "id": "Dhnz_7NODF-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flip_augmentation(original_images, augmented_images):\n",
        "  for image in original_images:\n",
        "      flipped = tf.image.flip_left_right(image)\n",
        "      augmented_images.append(flipped)\n",
        "\n",
        "  print(len(augmented_images))\n",
        "  plt.imshow(augmented_images[0])\n",
        "  plt.show()\n",
        "\n",
        "  for i, img in enumerate(augmented_images):\n",
        "      image_data = tf.cast(img * 255, tf.uint8)\n",
        "      numpy_image = image_data.numpy()\n",
        "      rgb_image = cv2.cvtColor(numpy_image, cv2.COLOR_BGR2RGB)\n",
        "      pil_image = Image.fromarray(rgb_image)\n",
        "      pil_image.save(os.path.join(output_folder_path, f'flipped_{i}.png'))\n",
        "\n",
        "augmented = []\n",
        "flip_augmentation(images, augmented)"
      ],
      "metadata": {
        "id": "W8excT6fD_Tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rotation_augmentation(paths, augmented_images):\n",
        "    ang_range = 30\n",
        "\n",
        "    for p in paths:\n",
        "        image = cv2.imread(p)\n",
        "        rows, cols, ch = image.shape\n",
        "\n",
        "        # Rotation\n",
        "        ang_rot = np.random.uniform(ang_range)-ang_range/2\n",
        "        Rot_M = cv2.getRotationMatrix2D((cols/2, rows/2),ang_rot,1)\n",
        "\n",
        "        image = cv2.warpAffine(image, Rot_M, (cols,rows))\n",
        "        augmented_images.append(image)\n",
        "\n",
        "    print(len(augmented_images))\n",
        "    plt.imshow(augmented_images[0])\n",
        "    plt.show()\n",
        "\n",
        "    for i, img in enumerate(augmented_images):\n",
        "        rgb_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        pil_image = Image.fromarray(rgb_image)\n",
        "        pil_image.save(os.path.join(output_folder_path, f'rotated_{i}.png'))\n",
        "\n",
        "augmented = []\n",
        "rotation_augmentation(file_paths, augmented)"
      ],
      "metadata": {
        "id": "QZelf273myni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translation_augmentation(paths, augmented_images):\n",
        "    trans_range = 50\n",
        "\n",
        "    for p in paths:\n",
        "        image = cv2.imread(p)\n",
        "        rows, cols, ch = image.shape\n",
        "\n",
        "        # Translation\n",
        "        tr_x = trans_range*np.random.uniform()-trans_range/2\n",
        "        tr_y = trans_range*np.random.uniform()-trans_range/2\n",
        "        Trans_M = np.float32([[1,0,tr_x], [0,1,tr_y]])\n",
        "\n",
        "        image = cv2.warpAffine(image, Trans_M, (cols,rows))\n",
        "        augmented_images.append(image)\n",
        "\n",
        "    print(len(augmented_images))\n",
        "    plt.imshow(augmented_images[0])\n",
        "    plt.show()\n",
        "\n",
        "    for i, img in enumerate(augmented_images):\n",
        "        rgb_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        pil_image = Image.fromarray(rgb_image)\n",
        "        pil_image.save(os.path.join(output_folder_path, f'translated_{i}.png'))\n",
        "\n",
        "augmented = []\n",
        "translation_augmentation(file_paths, augmented)"
      ],
      "metadata": {
        "id": "HFLwQL3vG6UX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def noise_augmentation(original_images, augmented_images):\n",
        "  for image in original_images:\n",
        "      noise = np.random.normal(0, 0.5, image.shape)\n",
        "      noisy_image = image + noise\n",
        "      noisy_image = np.clip(noisy_image, 0, 255)\n",
        "      augmented_images.append(noisy_image)\n",
        "\n",
        "  print(len(augmented_images))\n",
        "  plt.imshow(augmented_images[0])\n",
        "  plt.show()\n",
        "\n",
        "  for i, img in enumerate(augmented_images):\n",
        "      image_data = tf.cast(img * 255, tf.uint8)\n",
        "      numpy_image = image_data.numpy()\n",
        "      rgb_image = cv2.cvtColor(numpy_image, cv2.COLOR_BGR2RGB)\n",
        "      pil_image = Image.fromarray(rgb_image)\n",
        "      pil_image.save(os.path.join(output_folder_path, f'noisy_{i}.png'))\n",
        "\n",
        "augmented = []\n",
        "noise_augmentation(images, augmented)"
      ],
      "metadata": {
        "id": "o_4w93i8Zff2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}