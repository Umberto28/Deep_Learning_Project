{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1yRRCG7sQhQO4MTeTxjwLG5m1YBPgWCFY","authorship_tag":"ABX9TyO4Cz7SQEcqDVjegXolki7I"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Classificazione con metodi di Machine Learning**\n","Una volta estratte le features delle immagini del nostro dataset, le utilizziamo per la classificazione, comparando le prestazioni di quattro diversi modelli"],"metadata":{"id":"kUmkqyL_94Om"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"hkqo_F1aLCbo","executionInfo":{"status":"ok","timestamp":1709047676863,"user_tz":-60,"elapsed":4,"user":{"displayName":"Umberto Gentile","userId":"16878761636918124125"}}},"outputs":[],"source":["# Import generali\n","import pandas as pd\n","import numpy as np\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import AdaBoostClassifier"]},{"cell_type":"markdown","source":["### **Caricamento dei dati da Google drive (dataset non aumentato)**"],"metadata":{"id":"PITR49xy-y1R"}},{"cell_type":"code","source":["AM = ['', 'Crop', 'Rotated', 'Noisy', 'Flipped']\n","df = pd.DataFrame()\n","\n","# Creazione delle variabili features e labels dall'estrazione delle caratteristiche dell'architettura Xception\n","df = pd.read_csv(f'/content/drive/MyDrive/progetto_deep/Features/XceptionFeaturesAugg{AM[1]}.csv')\n","df.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n","labels_XC = df[\"diag\"]\n","df.drop([\"diag\"], axis=1, inplace=True)\n","features_XC = df.copy()\n","\n","# Creazione delle variabili features e labels dall'estrazione delle caratteristiche dell'architettura EfficientNet\n","df = pd.read_csv(f'/content/drive/MyDrive/progetto_deep/Features/EfficientNetFeaturesAugg{AM[1]}.csv')\n","df.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n","labels_EN = df[\"diag\"]\n","df.drop([\"diag\"], axis=1, inplace=True)\n","features_EN = df.copy()"],"metadata":{"id":"X48LNkMlNQ8f","executionInfo":{"status":"ok","timestamp":1709047702004,"user_tz":-60,"elapsed":22628,"user":{"displayName":"Umberto Gentile","userId":"16878761636918124125"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["### **1. Classificatore Naive Baies**"],"metadata":{"id":"-xukQLpI_oOo"}},{"cell_type":"code","source":["def naiveBayes(features, labels):\n","  # Sudivisione dei dati in set di addestramento e di test\n","  features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.20, random_state=42)\n","\n","  # Inizializzazione ed addestramento del classificatore\n","  clf = GaussianNB()\n","  clf.fit(features_train, labels_train)\n","\n","  # Predizioni sul set di test\n","  predictions = clf.predict(features_test)\n","\n","  # Stampe delle prestazioni\n","  accuracy = accuracy_score(labels_test, predictions)\n","  print(f'Accuracy: {accuracy}')\n","  print(classification_report(labels_test, predictions))\n","\n","print(\"Xception\")\n","naiveBayes(features_XC, labels_XC)\n","print(\"\\nEfficientNet\")\n","naiveBayes(features_EN, labels_EN)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gq6oGKcILLRP","executionInfo":{"status":"ok","timestamp":1709047708968,"user_tz":-60,"elapsed":422,"user":{"displayName":"Umberto Gentile","userId":"16878761636918124125"}},"outputId":"a42fbd34-2ac5-4791-8b23-2e1de9bc9145"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Xception\n","Accuracy: 0.652027027027027\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.54      0.63       162\n","           1       0.59      0.78      0.67       134\n","\n","    accuracy                           0.65       296\n","   macro avg       0.67      0.66      0.65       296\n","weighted avg       0.68      0.65      0.65       296\n","\n","\n","EfficientNet\n","Accuracy: 0.7263513513513513\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.79      0.76       162\n","           1       0.72      0.65      0.68       134\n","\n","    accuracy                           0.73       296\n","   macro avg       0.73      0.72      0.72       296\n","weighted avg       0.73      0.73      0.72       296\n","\n"]}]},{"cell_type":"markdown","source":["### **2. Classificatore K-Nearest Neighbours**"],"metadata":{"id":"W78iRpovAWzt"}},{"cell_type":"code","source":["def knn(features, labels, k):\n","  # Sudivisione dei dati in set di addestramento e di test\n","  features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.20, random_state=42)\n","\n","  # Standardizzazione delle features\n","  scaler = StandardScaler()\n","  features_train = scaler.fit_transform(features_train)\n","  features_test = scaler.transform(features_test)\n","\n","  # Inizializzazione ed addestramento del classificatore\n","  clf = KNeighborsClassifier(n_neighbors=k)\n","  clf.fit(features_train, labels_train)\n","\n","  # Predizioni sul set di test\n","  predictions = clf.predict(features_test)\n","\n","  # Stampe delle prestazioni\n","  accuracy = accuracy_score(labels_test, predictions)\n","  print(f'Accuracy: {accuracy}')\n","  print(classification_report(labels_test, predictions))\n","\n","print(\"Xception\")\n","knn(features_XC, labels_XC, 5)\n","print(\"\\nEfficientNet\")\n","knn(features_EN, labels_EN, 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hu58kMLPXJS3","executionInfo":{"status":"ok","timestamp":1709047779508,"user_tz":-60,"elapsed":707,"user":{"displayName":"Umberto Gentile","userId":"16878761636918124125"}},"outputId":"88e41398-8cf9-4950-f1c2-3fe0c91e0af3"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Xception\n","Accuracy: 0.7432432432432432\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.83      0.78       162\n","           1       0.76      0.63      0.69       134\n","\n","    accuracy                           0.74       296\n","   macro avg       0.75      0.73      0.74       296\n","weighted avg       0.75      0.74      0.74       296\n","\n","\n","EfficientNet\n","Accuracy: 0.8783783783783784\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.91      0.89       162\n","           1       0.88      0.84      0.86       134\n","\n","    accuracy                           0.88       296\n","   macro avg       0.88      0.88      0.88       296\n","weighted avg       0.88      0.88      0.88       296\n","\n"]}]},{"cell_type":"markdown","source":["### **3. Classificatore Random Forest**"],"metadata":{"id":"5u7uF-_PBOvn"}},{"cell_type":"code","source":["# Calcolo dell'accuracy media per 100 esecuzioni\n","def randomForestMean(estimator, x, y):\n","  total_acc=0\n","\n","  for i in range(100):\n","    # Sudivisione dei dati in set di addestramento e di test\n","    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 20, random_state=42)\n","\n","    # Inizializzazione ed addestramento del classificatore\n","    rnd_forest = RandomForestClassifier(n_estimators= estimator)\n","    rnd_forest.fit(X_train, y_train)\n","\n","    # Calcolo delle prestazioni\n","    total_acc += rnd_forest.score(X_test,y_test)\n","  return total_acc/100\n","\n","# Stampe delle prestazioni\n","print(\"Xception\")\n","print(\"Test accuracy of random forest classifier with n_estimators = 10 : {:.2f}\".format(randomForestMean(10, features_XC, labels_XC)))\n","print(\"Test accuracy of random forest classifier with n_estimators = 100 : {:.2f}\".format(randomForestMean(100, features_XC, labels_XC)))\n","print(\"\\nEfficientNet\")\n","print(\"Test accuracy of random forest classifier with n_estimators = 10 : {:.2f}\".format(randomForestMean(10, features_EN, labels_EN)))\n","print(\"Test accuracy of random forest classifier with n_estimators = 100 : {:.2f}\".format(randomForestMean(100, features_EN, labels_EN)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8dPbWAvABVKd","outputId":"29f444cd-76ff-4ce7-9c88-efa23445f89d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Xception\n","Test accuracy of random forest classifier with n_estimators = 10 : 0.75\n"]}]},{"cell_type":"markdown","source":["### **4. Classificatore Boosting**"],"metadata":{"id":"3FXG4S25FCdz"}},{"cell_type":"code","source":["# Calcolo dell'accuracy media per 100 esecuzioni\n","def boostingMean(estimator, x, y):\n","  total_acc=0\n","\n","  for i in range(100):\n","    # Sudivisione dei dati in set di addestramento e di test\n","    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 20, random_state=42)\n","\n","    # Inizializzazione ed addestramento del classificatore\n","    boost = AdaBoostClassifier(n_estimators=estimator, algorithm=\"SAMME\", random_state=0)\n","    boost.fit(X_train, y_train)\n","\n","    # Calcolo delle prestazioni\n","    total_acc += boost.score(X_test,y_test)\n","  return total_acc/100\n","\n","# Stampe delle prestazioni\n","print(\"Xception\")\n","print(\"Test accuracy of ada boosting classifier with n_estimators = 10 : {:.2f}\".format(boostingMean(10, features_XC, labels_XC)))\n","print(\"Test accuracy of ada boosting classifier with n_estimators = 50 : {:.2f}\".format(boostingMean(50, features_XC, labels_XC)))\n","print(\"Test accuracy of ada boosting classifier with n_estimators = 10 : {:.2f}\".format(boostingMean(10, features_EN, labels_EN)))\n","print(\"Test accuracy of ada boosting classifier with n_estimators = 50 : {:.2f}\".format(boostingMean(50, features_EN, labels_EN)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sejoq5DsFGRI","executionInfo":{"status":"ok","timestamp":1709047515848,"user_tz":-60,"elapsed":2093688,"user":{"displayName":"Umberto Gentile","userId":"16878761636918124125"}},"outputId":"adcfa034-6962-4301-80d8-911a2d847251"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Xception\n","Test accuracy of ada boosting classifier with n_estimators = 10 : 0.75\n","Test accuracy of ada boosting classifier with n_estimators = 50 : 0.80\n","Test accuracy of ada boosting classifier with n_estimators = 100 : 0.80\n","\n","EfficientNet\n","Test accuracy of ada boosting classifier with n_estimators = 10 : 0.65\n","Test accuracy of ada boosting classifier with n_estimators = 50 : 0.75\n","Test accuracy of ada boosting classifier with n_estimators = 100 : 0.75\n"]}]}]}
